{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e188b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "qd_client = QdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "122244dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d4f03001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMB_DIM = 512\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "collection_name = \"zoomcamp-rag-final-2\"\n",
    "\n",
    "qd_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size = EMB_DIM,\n",
    "        distance = models.Distance.COSINE # -1 a 1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09010a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    vector = models.Document(text=text, model=model_handle)\n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=vector,\n",
    "        payload=doc\n",
    "    )\n",
    "    points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "255e64b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "qd_client.upsert(collection_name=collection_name, points=points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97e407af",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"I just discovered the course. Can I Still join ? \"\n",
    "\n",
    "results = qd_client.query_points(\n",
    "        collection_name = collection_name,\n",
    "        query = models.Document(\n",
    "            text = question,\n",
    "            model = model_handle\n",
    "        ),\n",
    "        limit = 5,\n",
    "        with_payload = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bd5f12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryResponse(points=[ScoredPoint(id=450, version=0, score=0.8426586, payload={'text': 'The course is available in the self-paced mode too, so you can go through the materials at any time. But if you want to do it as a cohort with other students, the next iterations will happen in September 2023, September 2024 (and potentially other Septembers as well).', 'course': 'machine-learning-zoomcamp', 'section': 'General course-related questions'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=7, version=0, score=0.83405924, payload={'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.', 'course': 'data-engineering-zoomcamp', 'section': 'General course-related questions'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=455, version=0, score=0.8243949, payload={'text': 'We won’t re-record the course videos. The focus of the course and the skills we want to teach remained the same, and the videos are still up-to-date.\\nIf you haven’t taken part in the previous iteration, you can start watching the videos. It’ll be useful for you and you will learn new things. However, we recommend using Python 3.10 now instead of Python 3.8.', 'course': 'machine-learning-zoomcamp', 'section': 'General course-related questions'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=449, version=0, score=0.8219297, payload={'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.', 'course': 'machine-learning-zoomcamp', 'section': 'General course-related questions'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=436, version=0, score=0.81670785, payload={'text': 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.', 'course': 'machine-learning-zoomcamp', 'section': 'General course-related questions'}, vector=None, shard_key=None, order_value=None)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "035f9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "\n",
    "for point in results.points:\n",
    "    results_list.append(point.payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac574ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'The course is available in the self-paced mode too, so you can go through the materials at any time. But if you want to do it as a cohort with other students, the next iterations will happen in September 2023, September 2024 (and potentially other Septembers as well).',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': 'General course-related questions'},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions'},\n",
       " {'text': 'We won’t re-record the course videos. The focus of the course and the skills we want to teach remained the same, and the videos are still up-to-date.\\nIf you haven’t taken part in the previous iteration, you can start watching the videos. It’ll be useful for you and you will learn new things. However, we recommend using Python 3.10 now instead of Python 3.8.',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': 'General course-related questions'},\n",
       " {'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': 'General course-related questions'},\n",
       " {'text': 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': 'General course-related questions'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b43aeb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=2, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f54003b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"I just discovered the course. Can I Still join? \"\n",
    "\n",
    "\n",
    "def vector_search(query, limit = 1):\n",
    "    course = \"mlops-zoomcamp\"\n",
    "    resultados = qd_client.query_points(\n",
    "        collection_name = collection_name,\n",
    "        query = models.Document(\n",
    "            text = query,\n",
    "            model = model_handle\n",
    "        ),\n",
    "        query_filter = models.Filter(\n",
    "            must = [\n",
    "                models.FieldCondition(\n",
    "                    key = \"course\",\n",
    "                    match = models.MatchValue(value = course))\n",
    "                    ]\n",
    "        ),\n",
    "        limit = 5,\n",
    "        with_payload = True\n",
    "    )\n",
    "    results = []\n",
    "    print(\"resultados.points:\", resultados.points)\n",
    "    for point in resultados.points:\n",
    "        results.append(point.payload)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f3e974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultados.points: [ScoredPoint(id=857, version=0, score=0.77556765, payload={'text': \"You have something running on the 5000 port. You need to stop it.\\nAnswer: On terminal in mac .\\nRun ps -A | grep gunicorn\\nLook for the number process id which is the 1st number after running the command\\nkill 13580\\nwhere 13580  represents the process number.\\nSource\\nwarrie.warrieus@gmail.com\\nOr by executing the following command it will kill all the processes using port 5000:\\n>> sudo fuser -k 5000/tcp\\nAnswered by Vaibhav Khandelwal\\nJust execute in the command below in he command line to kill the running port\\n->> kill -9 $(ps -A | grep python | awk '{print $1}')\\nAnswered by kamaldeen (kamaldeen32@gmail.com)\\nChange to different port (5001 in this case)\\n>> mlflow ui --backend-store-uri sqlite:///mlflow.db --port 5001\\nAnswered by krishna (nellaikrishna@gmail.com)\", 'course': 'mlops-zoomcamp', 'section': 'Module 2: Experiment tracking'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=906, version=0, score=0.7681455, payload={'text': 'Ensure the correct image is being used to derive from.\\nCopy the data from local to the docker image using the COPY command to a relative path. Using absolute paths within the image might be troublesome.\\nUse paths starting from /app and don’t forget to do WORKDIR /app before actually performing the code execution.\\nMost common commands\\nBuild container using docker build -t mlops-learn .\\nExecute the script using docker run -it --rm mlops-learn\\n<mlops-learn> is just a name used for the image and does not have any significance.', 'course': 'mlops-zoomcamp', 'section': 'Module 4: Deployment'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=865, version=0, score=0.7622568, payload={'text': 'Make sure `mlflow.autolog()` ( or framework-specific autolog ) written BEFORE `with mlflow.start_run()` not after.\\nAlso make sure that all dependencies for the autologger are installed, including matplotlib. A warning about uninstalled dependencies will be raised.\\nMohammed Ayoub Chettouh', 'course': 'mlops-zoomcamp', 'section': 'Module 2: Experiment tracking'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=930, version=0, score=0.75990146, payload={'text': 'Solution. Using docker CLI run docker system prune to remove unused things (build cache, containers, images etc)\\nAlso, to see what’s taking space before pruning you can run docker system df\\nBy Alex Litvinov', 'course': 'mlops-zoomcamp', 'section': 'Module 5: Monitoring'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=866, version=0, score=0.7586892, payload={'text': 'If you’re running MLflow on a remote VM, you need to forward the port too like we did in Module 1 for Jupyter notebook port 8888. Simply connect your server to VS Code, as we did, and add 5000 to the PORT like in the screenshot:\\nAdded by Sharon Ibejih\\nIf you are running MLflow locally and 127.0.0.1:5000 shows a blank page navigate to localhost:5000 instead.', 'course': 'mlops-zoomcamp', 'section': 'Module 2: Experiment tracking'}, vector=None, shard_key=None, order_value=None)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': \"You have something running on the 5000 port. You need to stop it.\\nAnswer: On terminal in mac .\\nRun ps -A | grep gunicorn\\nLook for the number process id which is the 1st number after running the command\\nkill 13580\\nwhere 13580  represents the process number.\\nSource\\nwarrie.warrieus@gmail.com\\nOr by executing the following command it will kill all the processes using port 5000:\\n>> sudo fuser -k 5000/tcp\\nAnswered by Vaibhav Khandelwal\\nJust execute in the command below in he command line to kill the running port\\n->> kill -9 $(ps -A | grep python | awk '{print $1}')\\nAnswered by kamaldeen (kamaldeen32@gmail.com)\\nChange to different port (5001 in this case)\\n>> mlflow ui --backend-store-uri sqlite:///mlflow.db --port 5001\\nAnswered by krishna (nellaikrishna@gmail.com)\",\n",
       "  'course': 'mlops-zoomcamp',\n",
       "  'section': 'Module 2: Experiment tracking'},\n",
       " {'text': 'Ensure the correct image is being used to derive from.\\nCopy the data from local to the docker image using the COPY command to a relative path. Using absolute paths within the image might be troublesome.\\nUse paths starting from /app and don’t forget to do WORKDIR /app before actually performing the code execution.\\nMost common commands\\nBuild container using docker build -t mlops-learn .\\nExecute the script using docker run -it --rm mlops-learn\\n<mlops-learn> is just a name used for the image and does not have any significance.',\n",
       "  'course': 'mlops-zoomcamp',\n",
       "  'section': 'Module 4: Deployment'},\n",
       " {'text': 'Make sure `mlflow.autolog()` ( or framework-specific autolog ) written BEFORE `with mlflow.start_run()` not after.\\nAlso make sure that all dependencies for the autologger are installed, including matplotlib. A warning about uninstalled dependencies will be raised.\\nMohammed Ayoub Chettouh',\n",
       "  'course': 'mlops-zoomcamp',\n",
       "  'section': 'Module 2: Experiment tracking'},\n",
       " {'text': 'Solution. Using docker CLI run docker system prune to remove unused things (build cache, containers, images etc)\\nAlso, to see what’s taking space before pruning you can run docker system df\\nBy Alex Litvinov',\n",
       "  'course': 'mlops-zoomcamp',\n",
       "  'section': 'Module 5: Monitoring'},\n",
       " {'text': 'If you’re running MLflow on a remote VM, you need to forward the port too like we did in Module 1 for Jupyter notebook port 8888. Simply connect your server to VS Code, as we did, and add 5000 to the PORT like in the screenshot:\\nAdded by Sharon Ibejih\\nIf you are running MLflow locally and 127.0.0.1:5000 shows a blank page navigate to localhost:5000 instead.',\n",
       "  'course': 'mlops-zoomcamp',\n",
       "  'section': 'Module 2: Experiment tracking'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search('How do I Run Kafka', course = \"data-engineering-zoomcamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "520041d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36d44347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minha chave é: None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Minha chave é:\", os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f5fd6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)  # carrega o .env\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def llm(prompt):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1bedeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag (query):\n",
    "    search_results = vector_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d29fda06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultados.points: [ScoredPoint(id=857, version=0, score=0.7742764, payload={'text': \"You have something running on the 5000 port. You need to stop it.\\nAnswer: On terminal in mac .\\nRun ps -A | grep gunicorn\\nLook for the number process id which is the 1st number after running the command\\nkill 13580\\nwhere 13580  represents the process number.\\nSource\\nwarrie.warrieus@gmail.com\\nOr by executing the following command it will kill all the processes using port 5000:\\n>> sudo fuser -k 5000/tcp\\nAnswered by Vaibhav Khandelwal\\nJust execute in the command below in he command line to kill the running port\\n->> kill -9 $(ps -A | grep python | awk '{print $1}')\\nAnswered by kamaldeen (kamaldeen32@gmail.com)\\nChange to different port (5001 in this case)\\n>> mlflow ui --backend-store-uri sqlite:///mlflow.db --port 5001\\nAnswered by krishna (nellaikrishna@gmail.com)\", 'course': 'mlops-zoomcamp', 'section': 'Module 2: Experiment tracking'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=865, version=0, score=0.7677716, payload={'text': 'Make sure `mlflow.autolog()` ( or framework-specific autolog ) written BEFORE `with mlflow.start_run()` not after.\\nAlso make sure that all dependencies for the autologger are installed, including matplotlib. A warning about uninstalled dependencies will be raised.\\nMohammed Ayoub Chettouh', 'course': 'mlops-zoomcamp', 'section': 'Module 2: Experiment tracking'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=906, version=0, score=0.7661558, payload={'text': 'Ensure the correct image is being used to derive from.\\nCopy the data from local to the docker image using the COPY command to a relative path. Using absolute paths within the image might be troublesome.\\nUse paths starting from /app and don’t forget to do WORKDIR /app before actually performing the code execution.\\nMost common commands\\nBuild container using docker build -t mlops-learn .\\nExecute the script using docker run -it --rm mlops-learn\\n<mlops-learn> is just a name used for the image and does not have any significance.', 'course': 'mlops-zoomcamp', 'section': 'Module 4: Deployment'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=930, version=0, score=0.76487625, payload={'text': 'Solution. Using docker CLI run docker system prune to remove unused things (build cache, containers, images etc)\\nAlso, to see what’s taking space before pruning you can run docker system df\\nBy Alex Litvinov', 'course': 'mlops-zoomcamp', 'section': 'Module 5: Monitoring'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=823, version=0, score=0.7639506, payload={'text': 'If you create a folder data and download datasets or raw files in your local repository. Then to push all your code to remote repository without this files or folder please use gitignore file. The simple way to create it do the following steps\\n1. Create empty .txt file (using text editor or command line)\\n2. Safe as .gitignore (. must use the dot symbol)\\n3. Add rules\\n *.parquet - to ignore all parquet files\\ndata/ - to ignore all files in folder data\\n\\nFor more pattern read GIT documentation\\nhttps://git-scm.com/docs/gitignore\\nAdded by Olga Rudakova (olgakurgan@gmail.com)', 'course': 'mlops-zoomcamp', 'section': 'Module 1: Introduction'}, vector=None, shard_key=None, order_value=None)]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'question'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrag\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhow do I run kafka?\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mrag\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrag\u001b[39m (query):\n\u001b[32m      2\u001b[39m     search_results = vector_search(query)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     prompt = \u001b[43mbuild_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     answer = llm(prompt)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mbuild_prompt\u001b[39m\u001b[34m(query, search_results)\u001b[39m\n\u001b[32m     12\u001b[39m context = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m search_results:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     context = context + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc[\u001b[33m'\u001b[39m\u001b[33msection\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mquestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdoc\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33manswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m prompt = prompt_template.format(question=query, context=context).strip()\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prompt\n",
      "\u001b[31mKeyError\u001b[39m: 'question'"
     ]
    }
   ],
   "source": [
    "rag('how do I run kafka?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
